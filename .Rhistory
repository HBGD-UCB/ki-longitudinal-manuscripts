age_list = still_0,
label = "Still stunted")
stunt_pooled_corr = replace_zero(data = stunt_pooled_corr,
age_list = not_0,
label = "Not stunted")
stunt_pooled_corr = replace_zero(data = stunt_pooled_corr,
age_list = rec_0,
label = "Recovered")
stunt_pooled_corr = replace_zero(data = stunt_pooled_corr,
age_list = relapse_0,
label = "Stunting relapse")
stunt_pooled_corr = replace_zero(data = stunt_pooled_corr,
age_list = never_0,
label = "Never stunted")
stunt_pooled_corr_fe = replace_zero(data = stunt_pooled_fe,
age_list = newly_0,
label = "Newly stunted")
stunt_pooled_corr_fe = replace_zero(data = stunt_pooled_corr_fe,
age_list = still_0,
label = "Still stunted")
stunt_pooled_corr_fe = replace_zero(data = stunt_pooled_corr_fe,
age_list = not_0,
label = "Not stunted")
stunt_pooled_corr_fe = replace_zero(data = stunt_pooled_corr_fe,
age_list = rec_0,
label = "Recovered")
stunt_pooled_corr_fe = replace_zero(data = stunt_pooled_corr_fe,
age_list = relapse_0,
label = "Stunting relapse")
stunt_pooled_corr_fe = replace_zero(data = stunt_pooled_corr_fe,
age_list = never_0,
label = "Never stunted")
saveRDS(flow_m, file=paste0(res_dir, "stuntflow.RDS"))
saveRDS(stunt_pooled_corr, file=paste0(res_dir, "stuntflow_pooled.RDS"))
saveRDS(stunt_pooled_corr_fe, file=paste0(res_dir, "stuntflow_pooled_fe.RDS"))
##########################################
# ki longitudinal manuscripts
# stunting analysis
# create cohorts of children who
# recovered at different ages
##########################################
#-----------------------------------------
# Process data for stunting flow chart
#-----------------------------------------
rm(list=ls())
source(paste0(here::here(), "/0-config.R"))
d <- readRDS(paste0(ghapdata_dir, "stunting_data.rds"))
# since this will include recovery,
# subsetting to monthly cohorts
d <- d %>% filter(measurefreq=="monthly")
d = d %>% ungroup() %>% mutate(studyid = as.character(studyid))
##########################################
# Define indicators of stunting at each time point
##########################################
# define age windows
d = d %>%
mutate(agecat = case_when(
agedays==1 ~ "Birth",
agedays>1 & agedays<=3*30.4167 ~ "0-3 months",
agedays>3*30.4167 & agedays<=6*30.4167 ~ "3-6 months",
agedays>6*30.4167 & agedays<=9*30.4167 ~ "6-9 months",
agedays>9*30.4167 & agedays<=12*30.4167 ~ "9-12 months",
agedays>12*30.4167 & agedays<=15*30.4167 ~ "12-15 months",
agedays>15*30.4167 & agedays<=18*30.4167 ~"15-18 months",
agedays>18*30.4167 & agedays<=21*30.4167 ~ "18-21 months",
agedays>21*30.4167& agedays<=24*30.4167 ~ "21-24 months",
TRUE ~ ""
)) %>%
mutate(agecat=factor(agecat,levels=c("Birth","0-3 months","3-6 months","6-9 months",
"9-12 months","12-15 months","15-18 months",
"18-21 months","21-24 months")))
# check age categories
d %>%
group_by(agecat) %>%
summarise(n=sum(!is.na(agedays)),
min=min(agedays/30.4167),
mean=mean(agedays/30.4167),
max=max(agedays/30.4167))
# drop measurements with ages over 24 months
d = d %>% filter(!is.na(agecat))
# identify children who have recovered
ds = d %>%
group_by(studyid, country, subjid, agecat) %>%
arrange(studyid, country, subjid, agecat) %>%
mutate(maxage = max(agedays)) %>%
# get minimum haz in this age range
mutate(minhaz = min(haz)) %>%
# create indicator for whether the child
# was stunted in PREVIOUS age category
# but is no longer stunted
group_by(studyid, country, subjid) %>%
mutate(minhaz_prev = lag(minhaz)) %>%
mutate(cum_minhaz = cummin(minhaz)) %>%
mutate(prev_stunted = ifelse(minhaz >= -2 & cum_minhaz < -2, 1, 0)) %>%
mutate(prev_stunted = ifelse(is.na(minhaz_prev) &
agecat=="Birth", 0, prev_stunted ))
saveRDS(ds, file=paste0(res_dir, "stunt_rec_cohort.RDS"))
##########################################
# ki longitudinal manuscripts
# stunting analysis
# calculate mean difference in HAZ and HAZ velocity
# by sex within age strata
##########################################
rm(list=ls())
source(paste0(here::here(), "/0-config.R"))
source(paste0(here::here(),"/0-project-functions/0_descriptive_epi_shared_functions.R"))
source(paste0(here::here(),"/0-project-functions/0_descriptive_epi_stunt_functions.R"))
#-------------------------------------------
# Load and pre-process data
#-------------------------------------------
d <- readRDS(paste0(ghapdata_dir, "stunting_data.rds"))
head(d)
d <- d %>% subset(., select = -c(tr))
# using growth velocity cutoffs
d = d %>%
mutate(agecat=ifelse(agedays<3*30.4167,"0-3",
ifelse(agedays>=3*30.4167 & agedays<6*30.4167,"3-6",
ifelse(agedays>=6*30.4167 & agedays<9*30.4167,"6-9",
ifelse(agedays>=9*30.4167 & agedays<12*30.4167,"9-12",
ifelse(agedays>=12*30.4167 & agedays<15*30.4167,"12-15",
ifelse(agedays>=15*30.4167 & agedays<18*30.4167,"15-18",
ifelse(agedays>=18*30.4167 & agedays<21*30.4167,"18-21",
ifelse(agedays>=21*30.4167& agedays<24*30.4167,"21-24",""))))))))) %>%
mutate(agecat=factor(agecat,levels=c("0-3","3-6","6-9","9-12",
"12-15","15-18","18-21","21-24")))
d <- d %>%  filter(!is.na(agecat))
#-------------------------------------------
# function to fit the mean difference in haz by sex
#-------------------------------------------
est_mean_diff = function(data, age){
data_sub = data %>% filter(agecat == age)
# only run if there are sufficient observations
# within age, sex strata and that there are at least
# 100 observations in that age category
if(length(unique(data_sub$sex))==2 & nrow(data_sub)>100){
glm_fit = glm(haz ~ sex, data = data_sub)
yi = glm_fit$coefficients[2]
sei = sqrt(diag(vcov(glm_fit)))[2]
out = data.frame(agecat = age, yi = yi, sei = sei)
return(out)
}
}
#-------------------------------------------
# within each cohort, estimate the mean difference in haz
# by sex and age and save the mean difference and variance
#-------------------------------------------
cohort_list = as.list(unique(d$studyid))
agecat_list = unique(d$agecat)
meandiff_sex_list = list()
for(i in 1:length(cohort_list)){
print(paste0("studyid ", cohort_list[i]))
reslist = lapply(agecat_list, function(x) est_mean_diff(
data = d %>% filter(studyid==cohort_list[[i]]),
age = x
))
meandiff_sex_list[[i]] = bind_rows(reslist) %>%
mutate(studyid = cohort_list[[i]])
}
meandiff_sex_df = as.data.frame(bind_rows(meandiff_sex_list))
meandiff_sex_df = meandiff_sex_df %>% select(studyid, everything())
#-------------------------------------------
# function to pool using rma
#-------------------------------------------
fit_rma_diff = function(data, age){
fit = rma(yi = yi,  sei = sei,
method="REML", data = data %>% filter(agecat==age))
out = data.frame(
agecat = age,
est = fit$beta,
se = fit$se,
lb = fit$beta - 1.96 * fit$se,
ub = fit$beta + 1.96 * fit$se
)
rownames(out)=NULL
return(out)
}
#-------------------------------------------
# obtained pooled mean differences by sex by age
#-------------------------------------------
pooled_diff_age_list = lapply(agecat_list, function(x)
fit_rma_diff(data = meandiff_sex_df %>% filter(agecat==x), age =x))
pooled_diff_age_df = bind_rows(pooled_diff_age_list)
#-------------------------------------------
# save data
#-------------------------------------------
saveRDS(pooled_diff_age_df, file = paste0(res_dir, "haz_meandiff_sex.RDS"))
##########################################
# ki longitudinal manuscripts
# stunting analysis
# calculate mean difference in HAZ and HAZ velocity
# by sex within age strata
##########################################
rm(list=ls())
source(paste0(here::here(), "/0-config.R"))
source(paste0(here::here(),"/0-project-functions/0_descriptive_epi_shared_functions.R"))
source(paste0(here::here(),"/0-project-functions/0_descriptive_epi_stunt_functions.R"))
#-------------------------------------------
# Load and pre-process data
#-------------------------------------------
d <- readRDS(file=paste0(ghapdata_dir, "velocity_longfmt.rds"))
head(d)
d <- d %>% rename(agecat=diffcat)
#-------------------------------------------
# function to fit the mean difference in haz by sex
#-------------------------------------------
est_mean_diff = function(data, age){
data_sub = data %>% filter(agecat == age)
# only run if there are sufficient observations
# within age, sex strata and that there are at least
# 100 observations in that age category
if(length(unique(data_sub$sex))==2 & nrow(data_sub)>100){
glm_fit = glm(y_rate ~ sex, data = data_sub)
yi = glm_fit$coefficients[2]
sei = sqrt(diag(vcov(glm_fit)))[2]
out = data.frame(agecat = age, yi = yi, sei = sei)
return(out)
}
}
#-------------------------------------------
# within each cohort, estimate the mean difference in haz
# by sex and age and save the mean difference and variance
#-------------------------------------------
cohort_list = as.list(unique(d$studyid))
agecat_list = unique(d$agecat)
# Length velocity
meandiff_sex_list_lencm = list()
for(i in 1:length(cohort_list)){
print(paste0("studyid ", cohort_list[i]))
reslist = lapply(agecat_list, function(x) est_mean_diff(
data = d %>% filter(studyid==cohort_list[[i]] & ycat == "lencm"),
age = x
))
meandiff_sex_list_lencm[[i]] = bind_rows(reslist) %>%
mutate(studyid = cohort_list[[i]])
}
meandiff_sex_df_lencm = as.data.frame(bind_rows(meandiff_sex_list_lencm))
meandiff_sex_df_lencm = meandiff_sex_df_lencm %>% select(studyid, everything())
# laz velocity
meandiff_sex_list_LAZ = list()
for(i in 1:length(cohort_list)){
print(paste0("studyid ", cohort_list[i]))
reslist = lapply(agecat_list, function(x) est_mean_diff(
data = d %>% filter(studyid==cohort_list[[i]] & ycat == "haz"),
age = x
))
meandiff_sex_list_LAZ[[i]] = bind_rows(reslist) %>%
mutate(studyid = cohort_list[[i]])
}
meandiff_sex_df_LAZ = as.data.frame(bind_rows(meandiff_sex_list_LAZ))
meandiff_sex_df_LAZ = meandiff_sex_df_LAZ %>% select(studyid, everything())
#-------------------------------------------
# function to pool using rma
#-------------------------------------------
fit_rma_diff = function(data, age){
fit = rma(yi = yi,  sei = sei,
method="FE", data = data %>% filter(agecat==age))
out = data.frame(
agecat = age,
est = fit$beta,
se = fit$se,
lb = fit$beta - 1.96 * fit$se,
ub = fit$beta + 1.96 * fit$se
)
rownames(out)=NULL
return(out)
}
#-------------------------------------------
# obtained pooled mean differences by sex by age
#-------------------------------------------
pooled_diff_age_list_lencm = lapply(agecat_list, function(x)
fit_rma_diff(data = meandiff_sex_df_lencm %>% filter(agecat==x), age =x))
pooled_diff_age_list_laz = lapply(agecat_list, function(x)
fit_rma_diff(data = meandiff_sex_df_LAZ %>% filter(agecat==x), age =x))
pooled_diff_age_df_lencm = bind_rows(pooled_diff_age_list_lencm)
pooled_diff_age_df_laz = bind_rows(pooled_diff_age_list_laz)
#-------------------------------------------
# save data
#-------------------------------------------
saveRDS(pooled_diff_age_df_lencm, file = paste0(res_dir, "lencm_vel_meandiff_sex.RDS"))
saveRDS(pooled_diff_age_df_laz, file = paste0(res_dir, "haz_vel_meandiff_sex.RDS"))
#------------------------------------
# Household asset PCA
#------------------------------------
rm(list=ls())
library(dplyr)
library(tidyr)
library(SuperLearner)
library(washb)
library(tmle)
library(caret)
#Open log
#sink("U:/results/assetPCA-allstudies.txt")
#Function to calculate PCA of asset based wealth by enrollment
#Method based on: https://programming-r-pro-bro.blogspot.com/2011/10/principal-component-analysis-use.html
assetPCA<-function(dfull, varlist, reorder=F ){
varlist<-c("STUDYID","SUBJID","COUNTRY",varlist)
#Subset to only needed variables for subgroup analysis
ret <- dfull %>%
subset(select=c(varlist))
#Select assets
ret<-as.data.frame(ret)
id<-subset(ret, select=c("STUDYID","SUBJID","COUNTRY")) #drop subjectid
ret<-ret[,which(!(colnames(ret) %in% c("STUDYID","SUBJID","COUNTRY")))]
for(i in 1:ncol(ret)){
ret[,i]<-ifelse(ret[,i]=="",NA,ret[,i])
}
#drop rows with no asset data
id<-id[rowSums(is.na(ret[,4:ncol(ret)])) != ncol(ret)-3,]
ret<-ret[rowSums(is.na(ret[,4:ncol(ret)])) != ncol(ret)-3,]
#Drop assets with great missingness
for(i in 1:ncol(ret)){
cat(colnames(ret)[i],"\n")
print(table(is.na(ret[,i])))
print(class((ret[,i])))
}
#Set missingness to zero
table(is.na(ret))
for(i in 1:ncol(ret)){
ret[,i]<-as.character(ret[,i])
ret[is.na(ret[,i]),i]<-"miss"
ret[,i]<-as.factor(ret[,i])
}
table(is.na(ret))
#Remove columns with almost no variance
if(length(nearZeroVar(ret))>0){
ret<-ret[,-nearZeroVar(ret)]
}
#Convert factors into indicators
ret<-droplevels(ret)
ret<-design_matrix(ret)
if(length(nearZeroVar(ret))>0){
ret<-ret[,-nearZeroVar(ret)]
}
#Set missingness to zero
table(is.na(ret))
ret[is.na(ret)]<-0
table(is.na(ret))
#Remove columns with almost no variance
if(length(nearZeroVar(ret))>0){
ret<-ret[,-nearZeroVar(ret)]
}
## Convert the data into matrix ##
ret<-as.matrix(ret)
##Computing the principal component using eigenvalue decomposition ##
princ.return <- princomp(ret)
## To get the first principal component in a variable ##
load <- loadings(princ.return)[,1]
pr.cp <- ret %*% load  ## Matrix multiplication of the input data with the loading for the 1st PC gives us the 1st PC in matrix form.
HHwealth <- as.numeric(pr.cp) ## Gives us the 1st PC in numeric form in pr.
#Create 4-level household weath index
quartiles<-quantile(HHwealth, probs=seq(0, 1, 0.25))
print(quartiles)
ret<-as.data.frame(ret)
ret$HHwealth_quart<-rep(1, nrow(ret))
ret$HHwealth_quart[HHwealth>=quartiles[2]]<-2
ret$HHwealth_quart[HHwealth>=quartiles[3]]<-3
ret$HHwealth_quart[HHwealth>=quartiles[4]]<-4
table(ret$HHwealth_quart)
ret$HHwealth_quart<-factor(ret$HHwealth_quart)
if(reorder==T){
levels(ret$HHwealth_quart)<-c("Wealth Q4","Wealth Q3","Wealth Q2","Wealth Q1")
ret$HHwealth_quart<-factor(ret$HHwealth_quart, levels=c("Wealth Q1", "Wealth Q2","Wealth Q3","Wealth Q4"))
}else{
levels(ret$HHwealth_quart)<-c("Wealth Q1", "Wealth Q2","Wealth Q3","Wealth Q4")
}
#Table assets by pca quartile to identify wealth/poverty levels
d<-data.frame(id, ret)
wealth.tab <- d %>% subset(., select=-c(STUDYID, SUBJID, COUNTRY)) %>%
group_by(HHwealth_quart) %>%
summarise_all(funs(mean)) %>% as.data.frame()
print(wealth.tab)
#Save just the wealth data
pca.wealth<-d %>% subset(select=c(STUDYID, SUBJID, COUNTRY, HHwealth_quart))
pca.wealth$SUBJID<-as.numeric(as.character(pca.wealth$SUBJID))
d <-dfull %>% subset(., select=c("STUDYID","SUBJID","COUNTRY"))
d$SUBJID<-as.numeric(as.character(d$SUBJID))
d<-left_join(d, pca.wealth, by=c("STUDYID","SUBJID","COUNTRY"))
return(d)
}
#Identify studies measuring household assets
setwd("U:/data")
load("allGHAPstudies.Rdata")
colnames(d)
dim(d)
d<- d %>% subset(select=c(WHZ, shortid, STUDYID,  SUBJID, SEX, AGEDAYS, region, BICYCLE, CAR, CART, COOKFUEL, FRIG, MCYCLE, PHONE, RADIO, TV, WASHMAC, MOBILE, CHAIR, WATCH, SOFA, FAN, TABLE)) %>%
subset(!is.na(BICYCLE)|!is.na(CAR)|!is.na(CART)|!is.na(COOKFUEL)|!is.na(FRIG)|!is.na(MCYCLE)|!is.na(PHONE)|!is.na(RADIO)|!is.na(TV)|!is.na(WASHMAC)|!is.na(MOBILE)|!is.na(CHAIR)|
!is.na(WATCH)|!is.na(SOFA)|!is.na(FAN)|!is.na(TABLE)) %>%
filter(WHZ>-5 & WHZ <5)
dim(d)
table(d$STUDYID)
unique(d$shortid)
#---------
study<-"akup"
d<-readRDS(paste0("U:/data/",study,".rds")) %>% group_by(SUBJID) %>% arrange(AGEDAYS) %>% slice(1)
cat(paste(shQuote(colnames(d), type="cmd"), collapse=", "))
varlist<-colnames(d)[colnames(d) %in% c("NROOMS","BICYCLE",  "CAR","CART","COOKFUEL","ELEC","FRIG","MCYCLE",
"PHONE","RADIO", "SEWING",   "TV" ,"WASHMAC" )]
d<-assetPCA(d, varlist, reorder=T)
table(d$HHwealth_quart)
saveRDS(d, file=paste0(study, '.HHwealth.rds') )
-------------------------------------
#------------------------------------
# Household asset PCA
#------------------------------------
rm(list=ls())
source(paste0(here::here(), "/0-config.R"))
#Open log
#sink("U:/results/assetPCA-allstudies.txt")
#Function to calculate PCA of asset based wealth by enrollment
#Method based on: https://programming-r-pro-bro.blogspot.com/2011/10/principal-component-analysis-use.html
assetPCA<-function(dfull, varlist, reorder=F ){
varlist<-c("STUDYID","SUBJID","COUNTRY",varlist)
#Subset to only needed variables for subgroup analysis
ret <- dfull %>%
subset(select=c(varlist))
#Select assets
ret<-as.data.frame(ret)
id<-subset(ret, select=c("STUDYID","SUBJID","COUNTRY")) #drop subjectid
ret<-ret[,which(!(colnames(ret) %in% c("STUDYID","SUBJID","COUNTRY")))]
for(i in 1:ncol(ret)){
ret[,i]<-ifelse(ret[,i]=="",NA,ret[,i])
}
#drop rows with no asset data
id<-id[rowSums(is.na(ret[,4:ncol(ret)])) != ncol(ret)-3,]
ret<-ret[rowSums(is.na(ret[,4:ncol(ret)])) != ncol(ret)-3,]
#Drop assets with great missingness
for(i in 1:ncol(ret)){
cat(colnames(ret)[i],"\n")
print(table(is.na(ret[,i])))
print(class((ret[,i])))
}
#Set missingness to zero
table(is.na(ret))
for(i in 1:ncol(ret)){
ret[,i]<-as.character(ret[,i])
ret[is.na(ret[,i]),i]<-"miss"
ret[,i]<-as.factor(ret[,i])
}
table(is.na(ret))
#Remove columns with almost no variance
if(length(nearZeroVar(ret))>0){
ret<-ret[,-nearZeroVar(ret)]
}
#Convert factors into indicators
ret<-droplevels(ret)
ret<-design_matrix(ret)
if(length(nearZeroVar(ret))>0){
ret<-ret[,-nearZeroVar(ret)]
}
#Set missingness to zero
table(is.na(ret))
ret[is.na(ret)]<-0
table(is.na(ret))
#Remove columns with almost no variance
if(length(nearZeroVar(ret))>0){
ret<-ret[,-nearZeroVar(ret)]
}
## Convert the data into matrix ##
ret<-as.matrix(ret)
##Computing the principal component using eigenvalue decomposition ##
princ.return <- princomp(ret)
## To get the first principal component in a variable ##
load <- loadings(princ.return)[,1]
pr.cp <- ret %*% load  ## Matrix multiplication of the input data with the loading for the 1st PC gives us the 1st PC in matrix form.
HHwealth <- as.numeric(pr.cp) ## Gives us the 1st PC in numeric form in pr.
#Create 4-level household weath index
quartiles<-quantile(HHwealth, probs=seq(0, 1, 0.25))
print(quartiles)
ret<-as.data.frame(ret)
ret$HHwealth_quart<-rep(1, nrow(ret))
ret$HHwealth_quart[HHwealth>=quartiles[2]]<-2
ret$HHwealth_quart[HHwealth>=quartiles[3]]<-3
ret$HHwealth_quart[HHwealth>=quartiles[4]]<-4
table(ret$HHwealth_quart)
ret$HHwealth_quart<-factor(ret$HHwealth_quart)
if(reorder==T){
levels(ret$HHwealth_quart)<-c("Wealth Q4","Wealth Q3","Wealth Q2","Wealth Q1")
ret$HHwealth_quart<-factor(ret$HHwealth_quart, levels=c("Wealth Q1", "Wealth Q2","Wealth Q3","Wealth Q4"))
}else{
levels(ret$HHwealth_quart)<-c("Wealth Q1", "Wealth Q2","Wealth Q3","Wealth Q4")
}
#Table assets by pca quartile to identify wealth/poverty levels
d<-data.frame(id, ret)
wealth.tab <- d %>% subset(., select=-c(STUDYID, SUBJID, COUNTRY)) %>%
group_by(HHwealth_quart) %>%
summarise_all(funs(mean)) %>% as.data.frame()
print(wealth.tab)
#Save just the wealth data
pca.wealth<-d %>% subset(select=c(STUDYID, SUBJID, COUNTRY, HHwealth_quart))
pca.wealth$SUBJID<-as.numeric(as.character(pca.wealth$SUBJID))
d <-dfull %>% subset(., select=c("STUDYID","SUBJID","COUNTRY"))
d$SUBJID<-as.numeric(as.character(d$SUBJID))
d<-left_join(d, pca.wealth, by=c("STUDYID","SUBJID","COUNTRY"))
return(d)
}
#Identify studies measuring household assets
#setwd("U:/data")
#
# load("allGHAPstudies.Rdata")
# colnames(d)
#
#
# dim(d)
# d<- d %>% subset(select=c(WHZ, shortid, STUDYID,  SUBJID, SEX, AGEDAYS, region, BICYCLE, CAR, CART, COOKFUEL, FRIG, MCYCLE, PHONE, RADIO, TV, WASHMAC, MOBILE, CHAIR, WATCH, SOFA, FAN, TABLE)) %>%
#   subset(!is.na(BICYCLE)|!is.na(CAR)|!is.na(CART)|!is.na(COOKFUEL)|!is.na(FRIG)|!is.na(MCYCLE)|!is.na(PHONE)|!is.na(RADIO)|!is.na(TV)|!is.na(WASHMAC)|!is.na(MOBILE)|!is.na(CHAIR)|
#            !is.na(WATCH)|!is.na(SOFA)|!is.na(FAN)|!is.na(TABLE)) %>%
#   filter(WHZ>-5 & WHZ <5)
# dim(d)
# table(d$STUDYID)
# unique(d$shortid)
ghapdata_dir
here::here()
